{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Mastering Deep Learning\n",
        "###understanding a basic perceptron with both forward and backward propagation\n",
        "\n",
        "##Forward propagation:\n",
        "\n"
      ],
      "metadata": {
        "id": "PvifLO5nj9BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([[0.5], [0.8]])  # 2 input features\n",
        "y = 1  #target variables"
      ],
      "metadata": {
        "id": "bNspdT7bkzK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "W1 = np.random.randn(2, 2)   # weights for input → hidden layer (2x2)\n",
        "b1 = np.random.randn(2, 1)   # biases for hidden layer (2x1)\n",
        "\n",
        "W2 = np.random.randn(1, 2)   # weights for hidden → output (1x2)\n",
        "b2 = np.random.randn(1, 1)"
      ],
      "metadata": {
        "id": "JImrOeBNlcFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Activation functions"
      ],
      "metadata": {
        "id": "6mMmNYQ2lrSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "WKyQf3AOllVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###We use different activation functions for hidden and output layers"
      ],
      "metadata": {
        "id": "e3uoYfhVl8eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden Layer\n",
        "Z1 = np.dot(W1, X) + b1\n",
        "A1 = relu(Z1)\n",
        "\n",
        "# Output Layer\n",
        "Z2 = np.dot(W2, A1) + b2\n",
        "A2 = sigmoid(Z2)"
      ],
      "metadata": {
        "id": "70UD6Dnmlx_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output (A2):\", A2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ArUZlzmFli",
        "outputId": "788c615a-a427-4f72-cfc0-54ad4af95169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output (A2): [[0.92135202]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###the output that we get is using random weights so we have to check how close it is to the actual value, we can use a loss function (Log loss in this case)"
      ],
      "metadata": {
        "id": "I0mM2EROmPMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    epsilon = 1e-8  # to avoid log(0)\n",
        "    return - (y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))"
      ],
      "metadata": {
        "id": "Rbkt8YHfmJb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = binary_cross_entropy(y, A2)\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ0FhxHvkYmC",
        "outputId": "8c210f0d-63d0-4194-fab2-752f800468d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: [[0.08748879]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Back propagation and parameter tuning using gradient discent\n",
        "\n",
        "###we have to do back propagation for both the layer specific activation functions and update the weights"
      ],
      "metadata": {
        "id": "frorHdINkpEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Derivative of sigmoid\n",
        "def sigmoid_derivative(a):\n",
        "    return a * (1 - a)\n",
        "\n",
        "# Derivative of ReLU\n",
        "def relu_derivative(z):\n",
        "    return (z > 0).astype(float)"
      ],
      "metadata": {
        "id": "cS01bBzpkc_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Output layer\n",
        "dZ2 = A2 - y\n",
        "dW2 = np.dot(dZ2, A1.T)\n",
        "db2 = dZ2\n",
        "\n",
        "# Step 2: Hidden layer\n",
        "dA1 = np.dot(W2.T, dZ2)\n",
        "dZ1 = dA1 * relu_derivative(Z1)\n",
        "dW1 = np.dot(dZ1, X.T)\n",
        "db1 = dZ1"
      ],
      "metadata": {
        "id": "LKlnhKW0lrVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "W2 = W2 - learning_rate * dW2\n",
        "b2 = b2 - learning_rate * db2\n",
        "\n",
        "W1 = W1 - learning_rate * dW1\n",
        "b1 = b1 - learning_rate * db1"
      ],
      "metadata": {
        "id": "RSF96BG2l9cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building a 2 layered multi epoch neural network on realtime dataset (Breast cancer pediction)"
      ],
      "metadata": {
        "id": "tvImYOdevUhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load data\n",
        "data = load_breast_cancer()\n",
        "X = data.data     # features\n",
        "y = data.target   # labels (0 = benign, 1 = malignant)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape y to (n_samples, 1)\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "aRk1ADGBvp-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###always we use random weights and bias!!"
      ],
      "metadata": {
        "id": "OdbWPcujwVwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    np.random.seed(42)\n",
        "    W1 = np.random.randn(hidden_size, input_size) * 0.01\n",
        "    b1 = np.zeros((hidden_size, 1))\n",
        "    W2 = np.random.randn(output_size, hidden_size) * 0.01\n",
        "    b2 = np.zeros((output_size, 1))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "q3DEA3i4wBIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def relu_derivative(Z):\n",
        "    return (Z > 0).astype(float)\n",
        "\n",
        "def sigmoid(Z):\n",
        "    return 1 / (1 + np.exp(-Z))\n",
        "\n",
        "def sigmoid_derivative(A):\n",
        "    return A * (1 - A)"
      ],
      "metadata": {
        "id": "H50x40pdwf3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, W1, b1, W2, b2):\n",
        "    Z1 = np.dot(W1, X.T) + b1\n",
        "    A1 = relu(Z1)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)\n",
        "    cache = (Z1, A1, Z2, A2)\n",
        "    return A2, cache"
      ],
      "metadata": {
        "id": "R2H8I-qJwjRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(Y, A2):\n",
        "    m = Y.shape[0]\n",
        "    epsilon = 1e-8\n",
        "    log_loss = -np.mean(Y.T * np.log(A2 + epsilon) + (1 - Y.T) * np.log(1 - A2 + epsilon))\n",
        "    return log_loss"
      ],
      "metadata": {
        "id": "SgIlDBnIwmyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(X, Y, cache, W2):\n",
        "    Z1, A1, Z2, A2 = cache\n",
        "    m = X.shape[0]\n",
        "\n",
        "    dZ2 = A2 - Y.T\n",
        "    dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
        "\n",
        "    dA1 = np.dot(W2.T, dZ2)\n",
        "    dZ1 = dA1 * relu_derivative(Z1)\n",
        "    dW1 = (1/m) * np.dot(dZ1, X)\n",
        "    db1 = (1/m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "    return dW1, db1, dW2, 1/m * np.sum(dZ2, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "ZNGK-CxhwuBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, lr):\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "Ujcoxo31xMJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Actual training for 1000 epochs, each epoch has a forward and backward propagation"
      ],
      "metadata": {
        "id": "Ok_3yo-kxTrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X, Y, input_size=30, hidden_size=10, output_size=1, epochs=1000, lr=0.1):\n",
        "    W1, b1, W2, b2 = initialize_parameters(input_size, hidden_size, output_size)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        A2, cache = forward_propagation(X, W1, b1, W2, b2)\n",
        "        loss = compute_loss(Y, A2)\n",
        "        dW1, db1, dW2, db2 = backward_propagation(X, Y, cache, W2)\n",
        "        W1, b1, W2, b2 = update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, lr)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {i} - Loss: {loss:.4f}\")\n",
        "\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "a386rl-nxRDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1, W2, b2 = train(X_train, y_train, epochs=1000, lr=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMrZ-448x6MU",
        "outputId": "60a9b276-22a4-4a27-8785-5ff232e80ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Loss: 0.6932\n",
            "Epoch 100 - Loss: 0.1465\n",
            "Epoch 200 - Loss: 0.0753\n",
            "Epoch 300 - Loss: 0.0622\n",
            "Epoch 400 - Loss: 0.0560\n",
            "Epoch 500 - Loss: 0.0520\n",
            "Epoch 600 - Loss: 0.0492\n",
            "Epoch 700 - Loss: 0.0468\n",
            "Epoch 800 - Loss: 0.0448\n",
            "Epoch 900 - Loss: 0.0430\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating the model"
      ],
      "metadata": {
        "id": "s3OiJtr9yK0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, W1, b1, W2, b2):\n",
        "    A2, _ = forward_propagation(X, W1, b1, W2, b2)\n",
        "    return (A2 > 0.5).astype(int).T\n",
        "\n",
        "y_pred = predict(X_test, W1, b1, W2, b2)\n",
        "accuracy = np.mean(y_pred == y_test) * 100\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTWkZWxSx7jH",
        "outputId": "68934cbe-bfe2-448e-bfa0-4226e871ef1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.12%\n"
          ]
        }
      ]
    }
  ]
}