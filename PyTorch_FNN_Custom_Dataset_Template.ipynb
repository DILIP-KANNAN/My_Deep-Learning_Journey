{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c787d8",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è PyTorch FNN Template: Custom CSV Dataset\n",
    "This notebook helps you **train a Feedforward Neural Network on your own CSV dataset** using PyTorch.\n",
    "Adapt it easily for regression or classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c47dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Install PyTorch (Uncomment if needed)\n",
    "# !pip install torch torchvision pandas numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08837d79",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d1bd0",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your CSV path\n",
    "csv_path = 'your_dataset.csv'\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f93dbf",
   "metadata": {},
   "source": [
    "### üîπ Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target (replace 'target' with your column)\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece7f5a",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Create Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)  # Use float32 if regression\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700fb624",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Build the FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev_dim = h_dim\n",
    "        layers.append(nn.Linear(prev_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Model parameters\n",
    "input_dim = X.shape[1]\n",
    "hidden_dims = [64, 32]\n",
    "output_dim = len(np.unique(y))  # Adjust for regression (set = 1)\n",
    "\n",
    "model = FeedforwardNN(input_dim, hidden_dims, output_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950acad5",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For classification:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# For regression, use:\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7273ab9",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b125e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ba177",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ebc93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "‚úÖ You now have a complete **PyTorch FNN workflow for any CSV dataset**.\n",
    "\n",
    "Modify hidden layers, loss functions, and activation functions to experiment with your projects confidently."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
